<!DOCTYPE html>
<html>
<head>
<title>report.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="practical-work-04-%E2%80%93-deep-neural-networks">Practical Work 04 – Deep Neural Networks</h1>
<p>auhtors: Rachel Tranchida, Eva Ray</p>
<h2 id="introduction">Introduction</h2>
<p>Dans ce laboratoire, nous allons en premier lieu explorer trois méthodes différentes pour classer des images de chiffres provenant du jeu de données MNIST : un MLP, un MLP à partir de l'histogramme des gradients (HOG) et un réseau neuronal convolutif (CNN). Dans une seconde partie, nous allons ensuite créer un autre CNN qui devra être capable de classifier des radios thoraciques entre &quot;normal&quot; et &quot;pneumonie&quot;. Pour ce faire, nous allons travailler avec le framework <code>Keras</code>, qui est une bibliothèque d'outils liés aux réseaux de neuronea de haut niveau,  que nous avons déjà utilisé dans le laboratoire précédent.</p>
<h2 id="buts-p%C3%A9dagogiques">Buts Pédagogiques</h2>
<p>Les buts pédagogiques de ce laboratoire sont les suivants:</p>
<ul>
<li>Développer une meilleure compréhension de la différence entre <code>shallow</code> et <code>deep</code> neural networks.</li>
<li>Comprendre les principes fondamentaux des réseaux de neurones convolutifs.</li>
<li>Apprendre les bases du framework <code>Keras</code>.</li>
</ul>
<h2 id="partie-1">Partie 1</h2>
<h3 id="quel-est-lalgorithme-dapprentissage-utilis%C3%A9-pour-optimiser-les-poids-du-r%C3%A9seau-de-neurones">Quel est l'algorithme d'apprentissage utilisé pour optimiser les poids du réseau de neurones?</h3>
<p>L'algorithme utilisé pour optimisé les poids est <code>RMSprop</code>. RMSprop est un algorithme d'optimisation utilisé pour ajuster les poids d'un réseau de neurones. Il adapte les taux d'apprentissage des poids en utilisant une moyenne mobile des carrés des gradients précédents, ce qui permet une convergence plus rapide et une meilleure performance d'apprentissage.</p>
<div style="text-align:center">
    <img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-8.png" alt="drawing" style="width:300">
</div>
<p>où:</p>
<ul>
<li>E[g] est la moyenne mobile des gradients au carré</li>
<li>δc/δw est le gradient de la fonction de coût par rapport au poids</li>
<li>η est le taux d'apprentissage</li>
<li>β est le paramètre de la moyenne mobile</li>
</ul>
<h3 id="quels-sont-les-param%C3%A8tres-arguments-utilis%C3%A9s-par-cet-algorithme">Quels sont les paramètres (arguments) utilisés par cet algorithme?</h3>
<p>Les paramètres de l'algorithme <code>RMSprop</code> peuvent être trouvés dans la documentation de <code>Keras</code> et sont les suivants:</p>
<pre class="hljs"><code><div>keras.optimizers.RMSprop(
    learning_rate=<span class="hljs-number">0.001</span>,
    rho=<span class="hljs-number">0.9</span>,
    momentum=<span class="hljs-number">0.0</span>,
    epsilon=<span class="hljs-number">1e-07</span>,
    centered=<span class="hljs-literal">False</span>,
    weight_decay=<span class="hljs-literal">None</span>,
    clipnorm=<span class="hljs-literal">None</span>,
    clipvalue=<span class="hljs-literal">None</span>,
    global_clipnorm=<span class="hljs-literal">None</span>,
    use_ema=<span class="hljs-literal">False</span>,
    ema_momentum=<span class="hljs-number">0.99</span>,
    ema_overwrite_frequency=<span class="hljs-literal">None</span>,
    loss_scale_factor=<span class="hljs-literal">None</span>,
    gradient_accumulation_steps=<span class="hljs-literal">None</span>,
    name=<span class="hljs-string">"rmsprop"</span>,
    **kwargs
)
</div></code></pre>
<h3 id="quelle-fonction-de-loss-est-utilis%C3%A9e">Quelle fonction de loss est utilisée?</h3>
<p>La fonction de loss utilisée est <code>categorical_crossentropy</code>.
L'équation de la fonction de loss <code>categorical_crossentropy</code> est</p>
<pre class="hljs"><code><div>L = - ∑(y * log(y_pred))
</div></code></pre>
<p>où :</p>
<ul>
<li>L est la perte (loss) calculée pour un échantillon donné,</li>
<li>y représente les valeurs cibles réelles (sous forme d'un vecteur codé à chaud ou &quot;one-hot&quot;),</li>
<li>y_pred représente les probabilités prédites par le modèle pour chaque classe (également sous forme d'un vecteur).</li>
</ul>
<h2 id="partie-2">Partie 2</h2>
<h3 id="digit-recognition-from-raw-data">Digit Recognition from Raw Data</h3>
<p>Dans cet exercice, nous entraînons un réseaux de neurones en utilisant les données brutes des pixels de la base de données MNIST. Chaque chiffre de la base de données est une image de 28x28 pixels. Il y a 10 classes différentes, qui sont les chiffres de 0 à 9.</p>
<h4 id="mod%C3%A8le-1">Modèle 1</h4>
<h5 id="topologie-du-mod%C3%A8le">Topologie du modèle</h5>
<p>Vous trouvez ci-dessous les paramètres que nous avons choisi d'utiliser pour le premier modèle.</p>
<pre class="hljs"><code><div>model = Sequential()
model.add(Dense(<span class="hljs-number">512</span>, input_shape=(<span class="hljs-number">784</span>,), activation=<span class="hljs-string">'sigmoid'</span>))
<span class="hljs-comment">#model.add(Dropout(0.5))</span>
model.add(Dense(n_classes, activation=<span class="hljs-string">'softmax'</span>))
batch_size = <span class="hljs-number">128</span>
n_epoch = <span class="hljs-number">10</span>
</div></code></pre>
<p>Pour commencer, nous avons choisi d'ajouter des neurones dans la couche cachée en passant de 2 à 512, afin de donner une meilleure chance au modèle de capturer les motifs des données. Nous travaillons avec des images de chiffres, ce qui est une donnée relativement complexe donc un plus grand nombre de neurones a plus de chance de la comprendre.</p>
<p>Nous avons aussi augmenté le nombre d'epochs en passant de 3 à 10. Cela permet au modèle de passer par plus d'itérations d'apprentissage, ce qui peut améliorer sa capacité à converger vers une solution optimale. Ce choix est pertinent lorsque le modèle est plus complexe, comme dans notre cas avec 512 neurones dans la couche cachée.</p>
<p>Nous avons choisi de ne pas ajouter de couche dopout pour l'instant car le modèle ne montre pas de signe d'overfitting avec les paramètres actuels.</p>
<h5 id="poids-du-mod%C3%A8le">Poids du modèle</h5>
<p>Vous trouverez ci-dessous le résumé des poids et paramètres du modèle donné par la méthode <code>model.summary()</code> de <code>Keras</code>.</p>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace">&#x250F;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2533;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2533;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2513;
&#x2503;<span style="font-weight: bold"> Layer (type)                    </span>&#x2503;<span style="font-weight: bold"> Output Shape           </span>&#x2503;<span style="font-weight: bold">       Param # </span>&#x2503;
&#x2521;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2547;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2547;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2529;
&#x2502; dense_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            &#x2502;       <span style="color: #00af00; text-decoration-color: #00af00">401,920</span> &#x2502;
&#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
&#x2502; dense_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">10</span>)             &#x2502;         <span style="color: #00af00; text-decoration-color: #00af00">5,130</span> &#x2502;
&#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2534;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2534;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">407,050</span> (1.55 MB)
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">407,050</span> (1.55 MB)
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
<p>Pour calculer ces poids manuellement, on peut procéder couche par couche.</p>
<ul>
<li>Pour la première couche: (784 * 512) + 512 = 401'920</li>
<li>Pour la seconde couche (de sortie): (512 * 10) + 10 = 5'130</li>
</ul>
<p>Pour avoir le nombre total de poids, on additionne le nombre de poids de toutes les couches, ce qui nous donne 407'050 poids.</p>
<h5 id="graphique-de-lhistorique-dentra%C3%AEnement">Graphique de l'historique d'entraînement</h5>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image.png" alt="alt text"></p>
<h5 id="performances">Performances</h5>
<p>Test score: 0.09036532044410706</p>
<p>Test accuracy: 0.972599983215332</p>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-1.png" alt="alt text"></p>
<h5 id="analyse">Analyse</h5>
<p>Nous constatons sur notre training history plot que le nombre d'epochs est bien choisi pour ces paramètres car, bien que la courbe de training pourrait encore baisser, plus d'epochs amèneraient à de l'overfitting.</p>
<p>Les performances du modèles sont très bonnes, avec une accuracy de 0.973. On peut supposer que le jeu de données est relativement facile à apprendre car c'est une très bonne accuracy pour seulement 10 epochs de training. On remarquera aussi que dans ce cas la mesure 'accuracy' est pertinente car le dataset est bien équilibré.</p>
<p>En regardant la matrice de confusions, on constate qu'il y a certaines classes que le modèle confond particulièrement. En particulier, le modèle a du mal à différencier les classes 7 et 2, 9 et 4, 3 et 5. Cela semble pouvoir s'expliquer car ces chiffres se ressemblent à l'écrit et ont des particularités communes, ce qui les rend plus difficiles à différenencier pour le modèle.</p>
<p>Nous allons essayer de corriger ces imprécisions dans le second modèle.</p>
<h4 id="mod%C3%A8le-2">Modèle 2</h4>
<h5 id="topologie-du-mod%C3%A8le">Topologie du modèle</h5>
<p>Vous trouvez ci-dessous les paramètres que nous avons choisi d'utiliser pour le second modèle.</p>
<pre class="hljs"><code><div>batch_size = <span class="hljs-number">32</span>
n_epoch = <span class="hljs-number">20</span>
model = Sequential()
model.add(Dense(<span class="hljs-number">512</span>, input_shape=(<span class="hljs-number">784</span>,), activation=<span class="hljs-string">'sigmoid'</span>))
model.add(Dropout(<span class="hljs-number">0.5</span>))
model.add(Dense(n_classes, activation=<span class="hljs-string">'softmax'</span>))
</div></code></pre>
<p>Pour le second modèle, nous avons décidé d'ajouter une couche de dropout à 50%. En effet, nous avions constaté précedemment sur le training history plot que la courbe du training pouvait encore baisser mais que cela causerait de l'overfitting. Nous avons donc rajouté plus d'epochs en passant de 10 à 20 et nous espérons que la couche de dropout évitera l'overfitting.</p>
<p>Nous avons aussi décidé de descendre la batch size de 128 à 32. Avec une plus petite taille de batch, chaque mise à jour du modèle est basée sur un sous-ensemble plus restreint des données d'entraînement. Cela peut aider à diversifier les exemples présentés au modèle à chaque itération, ce qui peut l'aider à généraliser mieux sur les données de validation et de test. Nous espérons donc que cela va aider le modèle à distinguer mieux certaines classes.</p>
<h5 id="poids-du-mod%C3%A8le">Poids du modèle</h5>
<p>Vous trouverez ci-dessous le résumé des poids et paramètres du modèle donné par la méthode <code>model.summary()</code> de <code>Keras</code>.</p>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace">&#x250F;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2533;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2533;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2513;
&#x2503;<span style="font-weight: bold"> Layer (type)                    </span>&#x2503;<span style="font-weight: bold"> Output Shape           </span>&#x2503;<span style="font-weight: bold">       Param # </span>&#x2503;
&#x2521;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2547;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2547;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2529;
&#x2502; dense_19 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            &#x2502;       <span style="color: #00af00; text-decoration-color: #00af00">401,920</span> &#x2502;
&#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
&#x2502; dropout_7 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            &#x2502;             <span style="color: #00af00; text-decoration-color: #00af00">0</span> &#x2502;
&#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
&#x2502; dense_20 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">10</span>)             &#x2502;         <span style="color: #00af00; text-decoration-color: #00af00">5,130</span> &#x2502;
&#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2534;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2534;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">407,050</span> (1.55 MB)
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">407,050</span> (1.55 MB)
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
<p>Pour calculer ces poids manuellement, on peut procéder couche par couche.</p>
<ul>
<li>Pour la première couche: (784 * 512) + 512 = 401'920</li>
<li>La couche dropout ne possède pas de paramètres à entraîner.</li>
<li>Pour la seconde couche (de sortie): (512 * 10) + 10 = 5'130</li>
</ul>
<p>Pour avoir le nombre total de poids, on additionne le nombre de poids de toutes les couches, ce qui nous done 407'050 poids.</p>
<h5 id="graphique-de-lhistorique-dentra%C3%AEnement">Graphique de l'Historique d'Entraînement</h5>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-5.png" alt="alt text"></p>
<h5 id="performances">Performances</h5>
<p>Test score: 0.07116231322288513</p>
<p>Test accuracy: 0.9797999858856201</p>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-4.png" alt="alt text"></p>
<h5 id="analyse">Analyse</h5>
<p>Le training plot history est plutôt satisfaisant. Il aurait peut être fallu arrêter l'entraînement quelques epochs plus tôt car le modèle commence gentiment à overfitter. Le loss est plus bas que dans le modèle précédent, ce qui était notre but. On voit encore une fois que la courbe de training continue à descendre mais que dans notre cas continuer l'entraîenement plus longtemps causerait de l'overfitting.</p>
<p>L'accuracy est d'environ 0.98. Ce chiffre est légèrement mieux que précédemment et est très bon en général. On notera que quand les accuracy sont aussi hautes, il devient difficile de continuer à les améliorer.</p>
<p>Lorsqu'on regarde la matrice de confusion, on constate que le modèle a toujours du mal à différencier les classes 7 et 2, 9 et 4, 3 et 5 mais qu'il y a un petit peu moins de faux négatifs qu'avant. En particulier, le second modèle semble mieux différencier les classes 3 et 5 que le premier modèle.</p>
<h4 id="mod%C3%A8le-3">Modèle 3</h4>
<h5 id="topologie-du-mod%C3%A8le">Topologie du modèle</h5>
<p>Vous trouvez ci-dessous les paramètres que nous avons choisi d'utiliser pour le troisième modèle.</p>
<pre class="hljs"><code><div>batch_size = <span class="hljs-number">128</span>
n_epoch = <span class="hljs-number">30</span>
model = Sequential()
model.add(Dense(<span class="hljs-number">512</span>, input_shape=(<span class="hljs-number">784</span>,), activation=<span class="hljs-string">'sigmoid'</span>))
model.add(Dropout(<span class="hljs-number">0.5</span>))
model.add(Dense(<span class="hljs-number">256</span>, activation=<span class="hljs-string">"relu"</span>))
model.add(Dropout(<span class="hljs-number">0.5</span>))
model.add(Dense(n_classes, activation=<span class="hljs-string">'softmax'</span>))
</div></code></pre>
<p>Pour le modèle final, nous avons décidé de remettre une batch size de 128 car nous n'avions pas été spécialement s des bénéfices d'une batch size de 32.</p>
<p>Nous avons décidé de rajouter une couche cachée de 256 neurones et de fonction d'activation <code>relu</code>, suivie d'une nouvelle couche de dropout à 50%. Nous espérons que rajouter une couche aide le modèle à apprendre la complexité des images plus en détails et à différencier les classes problématiques.</p>
<p>Comme nous avons vu dans le training plot history précédent, la courbe de training continuait de descendre. Nous avons donc rajouté des epochs et nous passons de 20 à 30 epochs. Les couches de dropout devraient éviter d'avoir trop d'overfitting.</p>
<h5 id="poids-du-mod%C3%A8le">Poids du modèle</h5>
<p>Vous trouverez ci-dessous le résumé des poids et paramètres du modèle donné par la méthode <code>model.summary()</code> de <code>Keras</code>.</p>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace">&#x250F;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2533;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2533;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2513;
&#x2503;<span style="font-weight: bold"> Layer (type)                    </span>&#x2503;<span style="font-weight: bold"> Output Shape           </span>&#x2503;<span style="font-weight: bold">       Param # </span>&#x2503;
&#x2521;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2547;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2547;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2529;
&#x2502; dense_21 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            &#x2502;       <span style="color: #00af00; text-decoration-color: #00af00">401,920</span> &#x2502;
&#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
&#x2502; dropout_8 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            &#x2502;             <span style="color: #00af00; text-decoration-color: #00af00">0</span> &#x2502;
&#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
&#x2502; dense_22 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)            &#x2502;       <span style="color: #00af00; text-decoration-color: #00af00">131,328</span> &#x2502;
&#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
&#x2502; dropout_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)            &#x2502;             <span style="color: #00af00; text-decoration-color: #00af00">0</span> &#x2502;
&#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
&#x2502; dense_23 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">10</span>)             &#x2502;         <span style="color: #00af00; text-decoration-color: #00af00">2,570</span> &#x2502;
&#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2534;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2534;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">535,818</span> (2.04 MB)
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">535,818</span> (2.04 MB)
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
<p>Pour calculer ces poids manuellement, on peut procéder couche par couche.</p>
<ul>
<li>Pour la première couche: (784 * 512) + 512 = 401'920</li>
<li>La première couche de dropout ne possède pas de paramètres à entraîner.</li>
<li>Pour la seconde couche: (512 * 256) + 256 = 131'328</li>
<li>La seconde couche de dropout ne possède pas de paramètres à entraîner.</li>
<li>Pour la troisième couche (de sortie): (256 * 10) + 10 = 2'570</li>
</ul>
<p>Pour avoir le nombre total de poids, on additionne le nombre de poids de toutes les couches, ce qui nous done 535'818 poids.</p>
<h5 id="graphique-de-lhistorique-dentra%C3%AEnement">Graphique de l'historique d'entraînement</h5>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-3.png" alt="alt text"></p>
<h5 id="performances">Performances</h5>
<p>Test score: 0.07027491182088852</p>
<p>Test accuracy: 0.9817000031471252</p>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-2.png" alt="alt text"></p>
<h5 id="analyse">Analyse</h5>
<p>Le training history plot est très satisfaisant. Il n'y a pas d'overfitting avec 30 epochs pour ces paramètres. La courbe de training est très légèrement encore en train de descendre mais bien moins qu'avant.</p>
<p>L'accuracy est de 0.982, ce qui est la meilleure accuracy que nous avons eue jusqu'à présent. C'est une très bonne accuracy.</p>
<p>On constate dans la matrice de confusion que le modèle a toujours du mal avec les classes 4 et 9. Il fait aussi encore des erreurs d'identification entre les classes 2 et 7, 3 et 5 mais nettement moins qu'avec les autres modèles. Il serait bien sûr toujours possible d'améliorer ce modèle.</p>
<p>Ce dernier modèle est le modèle sélectionné pour la première expérience.</p>
<h3 id="digit-recognition-from-features-of-the-input-data">Digit recognition from features of the input data</h3>
<p>Dans cet exercice, nous entraînons un réseaux de neurones en utilisant les données brutes des pixels de la base de données MNIST. Cette fois, au lieu d'utiliser les images de 28x28 pixels comme inputs, nous calculons
les caractéristiques de l'histogramme des gradients (HOG) de parties de l'image et utilisons ces caractéristiques comme inputs pour le réseau de neurones.</p>
<h4 id="mod%C3%A8le-1">Modèle 1</h4>
<h5 id="topologie-du-mod%C3%A8le">Topologie du Modèle</h5>
<p>Vous trouvez ci-dessous les paramètres que nous avons choisi d'utiliser pour le premier modèle.</p>
<pre class="hljs"><code><div>batch_size = <span class="hljs-number">128</span>
n_epoch = <span class="hljs-number">50</span>
model = Sequential()
model.add(Dense(<span class="hljs-number">64</span>, input_shape=(hog_size,), activation=<span class="hljs-string">'relu'</span>))
model.add(Dropout(<span class="hljs-number">0.5</span>))
model.add(Dense(n_classes, activation=<span class="hljs-string">'softmax'</span>))
</div></code></pre>
<p>Pour commencer, nous avons choisi d'augmenter le nombre de neurones dans la couche cachée en passant de 2 à 64, afin de donner une chance au modèle de mieux appréhender les données.</p>
<p>Nous avons aussi augmenté le nombre d'epochs de 3 à 50 et avons donc aussi ajouté une couche de dropout pour minimiser l'overfitting.</p>
<h5 id="poids-du-mod%C3%A8le">Poids du modèle</h5>
<p>Vous trouverez ci-dessous le résumé des poids et paramètres du modèle donné par la méthode <code>model.summary()</code> de <code>Keras</code>.</p>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace">&#x250F;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2533;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2533;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2513;
&#x2503;<span style="font-weight: bold"> Layer (type)                    </span>&#x2503;<span style="font-weight: bold"> Output Shape           </span>&#x2503;<span style="font-weight: bold">       Param # </span>&#x2503;
&#x2521;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2547;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2547;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2529;
&#x2502; dense_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             &#x2502;        <span style="color: #00af00; text-decoration-color: #00af00">25,152</span> &#x2502;
&#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
&#x2502; dropout (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)               &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             &#x2502;             <span style="color: #00af00; text-decoration-color: #00af00">0</span> &#x2502;
&#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
&#x2502; dense_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">10</span>)             &#x2502;           <span style="color: #00af00; text-decoration-color: #00af00">650</span> &#x2502;
&#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2534;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2534;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">25,802</span> (100.79 KB)
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">25,802</span> (100.79 KB)
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
<p>Pour calculer ces poids manuellement, on peut procéder couche par couche.</p>
<ul>
<li>Pour la première couche: (392 * 64) + 64 = 25'152, où hog_size = 392</li>
<li>La première couche de dropout ne possède pas de paramètres à entraîner.</li>
<li>Pour la seconde couche: (640 * 10) + 10 = 650</li>
</ul>
<p>Pour avoir le nombre total de poids, on additionne le nombre de poids de toutes les couches, ce qui nous done 25'802 poids.</p>
<h5 id="graphique-de-lhistorique-dentra%C3%AEnement">Graphique de l'historique d'entraînement</h5>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-6.png" alt="alt text"></p>
<h5 id="performances">Performances</h5>
<p>Test score: 0.09391739219427109</p>
<p>Test accuracy: 0.9775999784469604</p>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-7.png" alt="alt text"></p>
<h5 id="analyse">Analyse</h5>
<p>Nous constatons que le training history plot est plutôt correct. Il n'y a pas d'overfitting. On constate que la courbe de training a peu baissé pendant les 10 à 20 dernières époques donc nous aurions pu potentiellement arrêter le training plus tôt.</p>
<p>L'accuracy est d'environ 0.978, ce qui est très bon. En regardant la matrice de confusion, on constate que le modèle a, comme pour la première expérience, du mal à distinguer certaines classes. En particulier, le modèle confond souvent les classes 5 et 3, 4 et 9, comme dans la première expérience mais aussi 7 et 9, 3 et 8 qui ne posaient pas particulièrement de problèmes lors de la première expérience. Les descripteurs HOG sont conçus pour être invariants à certaines transformations telles que la translation, l'échelle et la rotation. Cela peut rendre le modèle moins sensible à ces variations dans les données d'entrée, ce qui pourrait contribuer à une différence de classification pour certaines classes, en comparaison avec la première expérience.</p>
<p>On remarque aussi qu'en utilisant le HOG, le modèle n'a pas de mal à distinguer les classes 2 et 7 qui posaient problème en utilisant les images brutes. Il est possible que les caractéristiques extraites par le HOG aient permis au modèle de mieux distinguer ces deux classes.</p>
<h4 id="mod%C3%A8le-2">Modèle 2</h4>
<h5 id="topologie-du-mod%C3%A8le">Topologie du Modèle</h5>
<p>Vous trouvez ci-dessous les paramètres que nous avons choisi d'utiliser pour le second modèle.</p>
<pre class="hljs"><code><div>batch_size = <span class="hljs-number">128</span>
n_epoch = <span class="hljs-number">20</span>
model = Sequential()
model.add(Dense(<span class="hljs-number">64</span>, input_shape=(hog_size,), activation=<span class="hljs-string">'relu'</span>))
model.add(Dropout(<span class="hljs-number">0.5</span>))
model.add(Dense(n_classes, activation=<span class="hljs-string">'softmax'</span>))

n_orientations = <span class="hljs-number">16</span>
pix_p_cell = <span class="hljs-number">4</span>
hog_size = int(height * width * n_orientations / (pix_p_cell * pix_p_cell)) // =<span class="hljs-number">784</span>
</div></code></pre>
<p>Par rapport au premier modèle, nous avons réduit le nombre d'epoques, vu que la courbe de training du traininh history plot du premier modèle semblait stagner sur les dernières époques.</p>
<p>Nous avons aussi changé le nombre d'orientations en passant de 8 à 16, dans l'espoir que cela permette au HOG de capturer plus de détails dans les contours de l'image et que le modèle ait moins de mal à distinguer les classes problématiques.</p>
<h5 id="poids-du-mod%C3%A8le">Poids du modèle</h5>
<p>Vous trouverez ci-dessous le résumé des poids et paramètres du modèle donné par la méthode <code>model.summary()</code> de <code>Keras</code>.</p>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace">&#x250F;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2533;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2533;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2513;
&#x2503;<span style="font-weight: bold"> Layer (type)                    </span>&#x2503;<span style="font-weight: bold"> Output Shape           </span>&#x2503;<span style="font-weight: bold">       Param # </span>&#x2503;
&#x2521;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2547;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2547;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2501;&#x2529;
&#x2502; dense_18 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             &#x2502;        <span style="color: #00af00; text-decoration-color: #00af00">50,240</span> &#x2502;
&#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
&#x2502; dropout_7 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             &#x2502;             <span style="color: #00af00; text-decoration-color: #00af00">0</span> &#x2502;
&#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x253C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
&#x2502; dense_19 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                &#x2502; (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">10</span>)             &#x2502;           <span style="color: #00af00; text-decoration-color: #00af00">650</span> &#x2502;
&#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2534;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2534;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">50,890</span> (198.79 KB)
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">50,890</span> (198.79 KB)
</pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&apos;DejaVu Sans Mono&apos;,consolas,&apos;Courier New&apos;,monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
<p>Pour calculer ces poids manuellement, on peut procéder couche par couche.</p>
<ul>
<li>Pour la première couche: (784 * 64) + 64 = 50'240, où hog_size = 784</li>
<li>La première couche de dropout ne possède pas de paramètres à entraîner.</li>
<li>Pour la seconde couche: (640 * 10) + 10 = 650</li>
</ul>
<p>Pour avoir le nombre total de poids, on additionne le nombre de poids de toutes les couches, ce qui nous done 50'890 poids.</p>
<h5 id="graphique-de-lhistorique-dentra%C3%AEnement">Graphique de l'historique d'entraînement</h5>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-9.png" alt="alt text"></p>
<h5 id="performances">Performances</h5>
<p>Test score: 0.07377872616052628</p>
<p>Test accuracy: 0.9793999791145325</p>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-10.png" alt="alt text"></p>
<h5 id="analyse">Analyse</h5>
<p>Le training history plot est satisfaisant. Le trianing s'arrête avant d'overfitter et la courbe de training semble commencer à stagner donc ajouter des époques ne semble pas nécessaire.</p>
<p>L'accuracy est d'environ 0.979, ce qui est très bien. Cependant, cette accuracy est quasiment identique à celle du premier modèle, ce qui implique qu'ajouter des orientations au HOG n'a potentiellement pas beaucoup aidé le modèle à différencier les classes problématiques.</p>
<p>Lorsqu'on regarde la matrice de confusion, on constate que ce sont les mêmes classe qui sont difficiles à distinguer que pour le premier modèle mais que le nombre de faux négatif est un tout petit peu plus bas.</p>
<h4 id="mod%C3%A8le-3">Modèle 3</h4>
<h5 id="topologie-du-mod%C3%A8le">Topologie du Modèle</h5>
<p>Vous trouvez ci-dessous les paramètres que nous avons choisi d'utiliser pour le troisième modèle.</p>
<pre class="hljs"><code><div>batch_size = <span class="hljs-number">256</span>
n_epoch = <span class="hljs-number">10</span>
n_orientations = <span class="hljs-number">16</span>
pix_p_cell = <span class="hljs-number">4</span>
hog_size = int(height * width * n_orientations / (pix_p_cell * pix_p_cell))
model = Sequential()
model.add(Dense(<span class="hljs-number">128</span>, input_shape=(hog_size,), activation=<span class="hljs-string">'relu'</span>))
model.add(Dropout(<span class="hljs-number">0.5</span>))
model.add(Dense(n_classes, activation=<span class="hljs-string">'softmax'</span>))
</div></code></pre>
<p>Nous avons ajouté des neurones dans la couche cachée en passant de 64 à 128 pour donner une meilleure chance au modèle de comprendre la complexité des données. Nous avons aussi augmenté la batch size de 128 à 256 pour la même raison.</p>
<p>En contrepartie, nous avons baissé le nombre d'epochs de 20 à 10 pour minimiser l'overfitting.</p>
<h5 id="poids-du-mod%C3%A8le">Poids du Modèle</h5>
<p>Vous trouverez ci-dessous le résumé des poids et paramètres du modèle donné par la méthode <code>model.summary()</code> de <code>Keras</code>.</p>
<hr>
<h1 id="layer-type-output-shape-param">Layer (type)                Output Shape              Param #</h1>
<p>dense_19 (Dense)            (None, 128)               100480</p>
<p>dropout_9 (Dropout)         (None, 128)               0</p>
<p>dense_20 (Dense)            (None, 10)                1290</p>
<p>=================================================================
Total params: 101,770
Trainable params: 101,770
Non-trainable params: 0</p>
<hr>
<p>Pour calculer ces poids manuellement, on peut procéder couche par couche.</p>
<ul>
<li>Pour la première couche: (784 * 128) + 128 = 100'480, où hog_size = 784</li>
<li>La première couche de dropout ne possède pas de paramètres à entraîner.</li>
<li>Pour la seconde couche: (128 * 10) + 10 = 1290</li>
</ul>
<p>Pour avoir le nombre total de poids, on additionne le nombre de poids de toutes les couches, ce qui nous done 101'770 poids.</p>
<h5 id="graphique-de-lhistorique-dentra%C3%AEnement">Graphique de l'historique d'entraînement</h5>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-11.png" alt="alt text"></p>
<h5 id="performances">Performances</h5>
<p>Test score: 0.061707451939582825</p>
<p>Test accuracy: 0.9807999730110168</p>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-12.png" alt="alt text"></p>
<h5 id="analyse">Analyse</h5>
<p>En regardant le le training history plot, nous constatons que l'entraînement s'est arrêté à temps pour qu'il n'y ait pas d'overfitting. La courbe de training est encore légèrement en train de descendre et aurait pu bénéficier de quelques epochs d'entraînement en plus.</p>
<p>L'accuracy est de 0.981, ce qui est une très bonne accuracy et la meilleure que nous avons eue pour la seconde expérience. Ceci dit, cette accuracy, bien que meilleure, reste très proche de celle des autres modèles.</p>
<p>Lorsqu'on regarde la matrice de confusion, on constate que le modèle semble un peu meilleure que le précédent pour distinguer les classes problématiques. En effet, les nombres de faux négatifs sont un peu plus bas. Ceci dit, les classes qui sont le plus difficiles à distinguer restent 3 et 8, 3 et 5, 4 et 9, 7 et 9.</p>
<p>Ce modèle est le meilleur que nous avons créé pour la deuxième expérience, c'est donc celui-ci que nous sélectionnons.</p>
<h3 id="convolutional-neural-network-digit-recognition">Convolutional neural network digit recognition</h3>
<p>Dans cet exercice, nous allons entraîner un réseau de neurones convolutif capable de déterminer automatiquement les features pertinentes pour reconnaître les chiffre de 0 à 9.</p>
<h4 id="mod%C3%A8le-1">Modèle 1</h4>
<h5 id="topologie-du-mod%C3%A8le">Topologie du Modèle</h5>
<p>Vous trouvez ci-dessous les paramètres que nous avons choisi d'utiliser pour le second modèle.</p>
<pre class="hljs"><code><div>batch_size = <span class="hljs-number">128</span>
n_epoch = <span class="hljs-number">3</span>
l0 = Input(shape=(height, width, <span class="hljs-number">1</span>), name=<span class="hljs-string">'l0'</span>)

l1 = Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=<span class="hljs-string">'same'</span>, activation=<span class="hljs-string">'relu'</span>, name=<span class="hljs-string">'l1'</span>)(l0)
l1_mp = MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), name=<span class="hljs-string">'l1_mp'</span>)(l1)

l2 = Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=<span class="hljs-string">'same'</span>, activation=<span class="hljs-string">'relu'</span>, name=<span class="hljs-string">'l2'</span>)(l1)
l2_mp = MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), name=<span class="hljs-string">'l2_mp'</span>)(l2)

l3 = Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=<span class="hljs-string">'same'</span>, activation=<span class="hljs-string">'relu'</span>, name=<span class="hljs-string">'l3'</span>)(l2)
l3_mp = MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), name=<span class="hljs-string">'l3_mp'</span>)(l3)

flat = Flatten(name=<span class="hljs-string">'flat'</span>)(l3_mp)

l4 = Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>, name=<span class="hljs-string">'l4'</span>)(flat)
l5 = Dense(n_classes, activation=<span class="hljs-string">'softmax'</span>, name=<span class="hljs-string">'l5'</span>)(l4)

model = Model(inputs=l0, outputs=l5)
</div></code></pre>
<p>Pour ce premier modèle, nous avons décidé d'augmenter le nombre de filtres de 2 à 32 et le nombre de neurones dans la couche cachée de 2 à 64 pour extraire les caractérsitiques plus complexes des données.</p>
<h5 id="poids-du-mod%C3%A8le">Poids du Modèle</h5>
<p>Vous trouverez ci-dessous le résumé des poids et paramètres du modèle donné par la méthode <code>model.summary()</code> de <code>Keras</code>.</p>
<p>Model: &quot;model_1&quot;</p>
<hr>
<h1 id="layer-type-output-shape-param">Layer (type)                Output Shape              Param #</h1>
<p>l0 (InputLayer)             [(None, 28, 28, 1)]       0</p>
<p>l1 (Conv2D)                 (None, 28, 28, 32)        160</p>
<p>l2 (Conv2D)                 (None, 28, 28, 32)        4128</p>
<p>l3 (Conv2D)                 (None, 28, 28, 32)        4128</p>
<p>l3_mp (MaxPooling2D)        (None, 14, 14, 32)        0</p>
<p>flat (Flatten)              (None, 6272)              0</p>
<p>l4 (Dense)                  (None, 64)                401472</p>
<p>l5 (Dense)                  (None, 10)                650</p>
<p>=================================================================
Total params: 410,538
Trainable params: 410,538
Non-trainable params: 0</p>
<hr>
<p>Pour calculer ces poids manuellement, on peut procéder couche par couche.</p>
<ul>
<li>
<p>Couche de convolution l1 :
Nombre de filtres : 32
Taille des filtres : (2, 2)
Profondeur des filtres (canaux d'entrée) : 1 (images en niveaux de gris)
Nombre de poids par filtre : (2 * 2 * 1) + 1 (biais) = 5
Nombre total de poids : 32 * 5 = 160</p>
</li>
<li>
<p>Couche de convolution l2 :
Nombre de filtres : 32
Taille des filtres : (2, 2)
Profondeur des filtres (canaux d'entrée) : 32 (sortie de la couche l1)
Nombre de poids par filtre : (2 * 2 * 32) + 1 (biais) = 129
Nombre total de poids : 32 * 129 = 4128</p>
</li>
<li>
<p>Couche de convolution l3 :
Nombre de filtres : 32
Taille des filtres : (2, 2)
Profondeur des filtres (canaux d'entrée) : 32 (sortie de la couche l2)
Nombre de poids par filtre : (2 * 2 * 32) + 1 (biais) = 129
Nombre total de poids : 32 * 129 = 4128</p>
</li>
<li>
<p>Couche dense l4 :
Nombre de neurones : 64
Taille de l'entrée aplatie : 14 * 14 * 32 = 6272
Nombre de poids : (6272 * 64) + 64 (biais) = 401'472</p>
</li>
<li>
<p>Couche dense l5 :
Nombre de neurones : 10 (nombre de classes dans le problème de classification)
Taille de l'entrée : 64 (sortie de la couche l4)
Nombre de poids : (64 * 10) + 10 (biais) = 650</p>
</li>
</ul>
<p>Pour avoir le nombre total de poids, on additionne le nombre de poids de toutes les couches, ce qui nous done 410'538 poids.</p>
<h5 id="graphique-de-lhistorique-dentra%C3%AEnement">Graphique de l'historique d'entraînement</h5>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-13.png" alt="alt text"></p>
<h5 id="performances">Performances</h5>
<p>Test score: 0.04008874669671059</p>
<p>Test accuracy: 0.9872000217437744</p>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-14.png" alt="alt text"></p>
<h5 id="analyse">Analyse</h5>
<h4 id="mod%C3%A8le-2">Modèle 2</h4>
<h5 id="topologie-du-mod%C3%A8le">Topologie du Modèle</h5>
<pre class="hljs"><code><div>l0 = Input(shape=(height, width, <span class="hljs-number">1</span>), name=<span class="hljs-string">'l0'</span>)

l1 = Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=<span class="hljs-string">'same'</span>, activation=<span class="hljs-string">'relu'</span>, name=<span class="hljs-string">'l1'</span>)(l0)
l1_mp = MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), name=<span class="hljs-string">'l1_mp'</span>)(l1)

l2 = Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=<span class="hljs-string">'same'</span>, activation=<span class="hljs-string">'relu'</span>, name=<span class="hljs-string">'l2'</span>)(l1)
l2_mp = MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), name=<span class="hljs-string">'l2_mp'</span>)(l2)

l3 = Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=<span class="hljs-string">'same'</span>, activation=<span class="hljs-string">'relu'</span>, name=<span class="hljs-string">'l3'</span>)(l2)
l3_mp = MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), name=<span class="hljs-string">'l3_mp'</span>)(l3)

flat = Flatten(name=<span class="hljs-string">'flat'</span>)(l3_mp)

l4 = Dense(<span class="hljs-number">128</span>, activation=<span class="hljs-string">'relu'</span>, name=<span class="hljs-string">'l4'</span>)(flat)
l4_drop = Dropout(<span class="hljs-number">0.5</span>)(l4)

l5 = Dense(n_classes, activation=<span class="hljs-string">'softmax'</span>, name=<span class="hljs-string">'l5'</span>)(l4_drop)

model = Model(inputs=l0, outputs=l5)
</div></code></pre>
<h5 id="poids-du-mod%C3%A8le">Poids du Modèle</h5>
<p>Vous trouverez ci-dessous le résumé des poids et paramètres du modèle donné par la méthode <code>model.summary()</code> de <code>Keras</code>.</p>
<p>Model: &quot;model_10&quot;</p>
<hr>
<h1 id="layer-type-output-shape-param">Layer (type)                Output Shape              Param #</h1>
<p>l0 (InputLayer)             [(None, 28, 28, 1)]       0</p>
<p>l1 (Conv2D)                 (None, 28, 28, 32)        160</p>
<p>l2 (Conv2D)                 (None, 28, 28, 32)        4128</p>
<p>l3 (Conv2D)                 (None, 28, 28, 32)        4128</p>
<p>l3_mp (MaxPooling2D)        (None, 14, 14, 32)        0</p>
<p>flat (Flatten)              (None, 6272)              0</p>
<p>l4 (Dense)                  (None, 128)               802944</p>
<p>dropout_7 (Dropout)         (None, 128)               0</p>
<p>l5 (Dense)                  (None, 10)                1290</p>
<p>=================================================================
Total params: 812,650
Trainable params: 812,650
Non-trainable params: 0</p>
<hr>
<p>Pour calculer ces poids manuellement, on peut procéder couche par couche.</p>
<p>Pour avoir le nombre total de poids, on additionne le nombre de poids de toutes les couches, ce qui nous done 812'650 poids.</p>
<h5 id="graphique-de-lhistorique-dentra%C3%AEnement">Graphique de l'historique d'entraînement</h5>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-15.png" alt="alt text"></p>
<h5 id="performances">Performances</h5>
<p>Test score: 0.0349692776799202</p>
<p>Test accuracy: 0.988099992275238</p>
<p><img src="file:///c:/Users/evara/Desktop/HEIG/semestre_4_2023-2024/ARN/PW4_ARN/documentation/image-16.png" alt="alt text"></p>
<h5 id="analyse">Analyse</h5>
<h4 id="mod%C3%A8le-3">Modèle 3</h4>
<h5 id="topologie-du-mod%C3%A8le">Topologie du Modèle</h5>
<h5 id="poids-du-mod%C3%A8le">Poids du Modèle</h5>
<p>Vous trouverez ci-dessous le résumé des poids et paramètres du modèle donné par la méthode <code>model.summary()</code> de <code>Keras</code>.</p>
<p>Pour calculer ces poids manuellement, on peut procéder couche par couche.</p>
<p>Pour avoir le nombre total de poids, on additionne le nombre de poids de toutes les couches, ce qui nous done 812'650 poids.</p>
<h5 id="graphique-de-lhistorique-dentra%C3%AEnement">Graphique de l'historique d'entraînement</h5>
<h5 id="performances">Performances</h5>
<h2 id="partie-3">Partie 3</h2>
<h3 id="les-mod%C3%A8les-cnn-sont-plus-profonds-ont-plus-de-couches-ont-ils-plus-de-poids-que-les-mod%C3%A8les-shallow">Les modèles CNN sont plus profonds (ont plus de couches), ont-ils plus de poids que les modèles shallow?</h3>
<p>En général, les réseaux de neurones convolutifs (CNN) plus profonds ont tendance à avoir plus de poids que les modèles shallow. Cela est dû au fait que les CNN plus profonds ont généralement un plus grand nombre de couches, et chaque couche est composée de plusieurs filtres qui contiennent des poids.</p>
<h3 id="exemple">Exemple</h3>
<h1 id="a-verifier-cest-fait-par-claude">A VERIFIER CEST FAIT PAR CLAUDE</h1>
<p>Supposons que nous ayons un CNN superficiel avec une seule couche de convolution suivie d'une couche entièrement connectée. La couche de convolution a 16 filtres de taille 3x3, et la couche entièrement connectée a 128 neurones. Dans ce cas, le nombre de poids dans la couche de convolution serait de 16 * (3 * 3) = 144, et le nombre de poids dans la couche entièrement connectée serait (16 * 3 * 3) * 128 = 73 728. Ainsi, le nombre total de poids dans le CNN superficiel serait de 73 728 + 144 = 73 872.</p>
<p>Maintenant, considérons un CNN plus profond avec trois couches de convolution, chacune suivie d'une couche de mise en commun (pooling), puis d'une couche entièrement connectée. Chaque couche de convolution a 32 filtres de taille 3x3, et la couche entièrement connectée a 256 neurones. Dans ce cas, le nombre de poids dans chaque couche de convolution serait de 32 * (3 * 3) = 288, et le nombre de poids dans la couche entièrement connectée serait (32 * 3 * 3) * 256 = 294 912. Ainsi, le nombre total de poids dans le CNN plus profond serait (288 * 3) + 294 912 = 295 776.</p>
<h2 id="partie-4">Partie 4</h2>

</body>
</html>
